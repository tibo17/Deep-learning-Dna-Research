import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt
import numpy as np
import math




## parameters of the neural network
num_epochs = 30
batch_size = 5
learning_rate = 0.001

pattern = "A[CG]A"
length_sequence = 20
nb_samples = 1000


##Dna class used to create the dataset
class Dna(Dataset):

    def __init__(self, pattern, length_sequence, nb_samples):

        self.input = dataset_input_creation(pattern, length_sequence, nb_samples)
        self.output = dataset_output_creation(nb_samples)
        self.pattern = pattern
        self.length_sequence = length_sequence
        self.nb_samples = nb_samples


    def __getitem__(self, index):
        return self.input[index], self.output[index]


    def __len__(self):
        return self.nb_samples



##Creation of the dataset

#data for the training loop
dataset = Dna(pattern, length_sequence, nb_samples)

dataloader = DataLoader(dataset = dataset, batch_size = 5, shuffle = True)

dataiter = iter(dataloader)

input, labels = dataiter.next()

total_samples = len(dataset)

#data for the test
datasettest =  Dna(pattern, length_sequence, 10)

dataloadertest = dataloader = DataLoader(dataset = datasettest, batch_size = 1, shuffle = True)



##ConvNet neural network class

class ConvNet(nn.Module):

    def __init__(self):
        super(ConvNet, self).__init__()
        self.conv1 = nn.Conv1d(4, 1, 3)
        self.conv2 = nn.Conv1d(1, 1, 3)
        self.fc = nn.Linear(length_sequence-4, 1)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = x.view(-1, length_sequence-4)
        x = F.relu(self.fc(x))
        return x


## Training loop

model = ConvNet()
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)




for epoch in range(100):
    for i, (input, labels) in enumerate(dataloader):


        prediction = model(input)
        loss = nn.MSELoss()
        l = loss(labels, prediction)
   

        optimizer.zero_grad()
        l.backward()
        optimizer.step()

## Test loop
  
for epoch in range(1):
    for i, (input, labels) in enumerate(dataloadertest):


        prediction = model(input)
        loss = nn.MSELoss()
        l = loss(labels, prediction)
        print(" ")
        print(prediction)
        print(labels)
        print(l)
        print(" ")
   

  
  
  
